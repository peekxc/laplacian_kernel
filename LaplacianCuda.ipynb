{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 'mamba init' to be able to run mamba activate/deactivate\n",
      "and start a new shell session. Or use conda to activate/deactivate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!miniforge3/bin/mamba activate laplacian2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install cupy numba; # pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGGGEc1-WxYl",
    "outputId": "346537de-05b2-45f1-83a8-0b15d31b6a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: combin in ./.local/lib/python3.9/site-packages (0.1.3)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.9/site-packages (from combin) (1.26.4)\n",
      "Requirement already satisfied: more_itertools in ./.local/lib/python3.9/site-packages (from combin) (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install combin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting cupy\n",
      "  Using cached cupy-13.1.0.tar.gz (3.5 MB)\n",
      "Requirement already satisfied: numpy<1.29,>=1.22 in ./.local/lib/python3.9/site-packages (from cupy) (1.26.4)\n",
      "Requirement already satisfied: fastrlock>=0.5 in ./.local/lib/python3.9/site-packages (from cupy) (0.8.2)\n",
      "Building wheels for collected packages: cupy\n",
      "  Building wheel for cupy (setup.py) ... \u001b[?25l|"
     ]
    }
   ],
   "source": [
    "!pip3 install cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bkGWOMc-WVCj"
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 22, 32, 45, 64, 90, 128, 181, 256, 362, 512, 724, 1024, 1448]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [int(2**k) for k in [3,3.5,4,4.5,5,5.5,6,6.5,7]]\n",
    "# 16,32,64,128,256,512,1024,2048\n",
    "[int(2**k) for k in np.arange(4,11,0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQYmJWP5Vz6E"
   },
   "outputs": [],
   "source": [
    "do_bounds_check = True\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def get_max(top: int, bottom: int, pred: Callable, *args):\n",
    "  if ~pred(bottom, *args):\n",
    "    return bottom\n",
    "  size = (top - bottom)\n",
    "  while (size > 0):\n",
    "    step = size >> 1\n",
    "    mid = top - step\n",
    "    if ~pred(mid, *args):\n",
    "      top = mid - 1\n",
    "      size -= step + 1\n",
    "    else:\n",
    "      size = step\n",
    "  return top\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def find_k_pred(w: int, r: int, m: int, BT: np.ndarray) -> bool:\n",
    "  return BT[m][w] <= r\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def get_max_vertex(r: int, m: int, n: int, BT: np.ndarray) -> int:\n",
    "  k_lb: int = m - 1\n",
    "  return 1 + get_max(n, k_lb, find_k_pred, r, m, BT)\n",
    "\n",
    "@nb.jit(nopython=True,boundscheck=do_bounds_check)\n",
    "def k_boundary_cpu(n: int, simplex: int, dim: int, BT: np.ndarray, out: np.ndarray):\n",
    "  idx_below: int = simplex\n",
    "  idx_above: int = 0\n",
    "  j = n - 1\n",
    "  for k in np.flip(np.arange(dim+1)):\n",
    "    j = get_max_vertex(idx_below, k + 1, j, BT) - 1\n",
    "    c = BT[k+1][j]\n",
    "    face_index = idx_above - c + idx_below\n",
    "    idx_below -= c\n",
    "    idx_above += BT[k][j]\n",
    "    out[dim-k] = face_index\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def laplacian0_matvec(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  np.multiply(x, deg, y) # y = x * deg\n",
    "  ps = np.zeros(2, dtype=np.int32)\n",
    "  for tid in range(N):\n",
    "    k_boundary_cpu(n, tid, k - 1, BT, ps)\n",
    "    a,b = ps\n",
    "    y[a] -= x[b]\n",
    "    y[b] -= x[a]\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def laplacian1_matvec(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  np.multiply(x, deg, y) # y = x * deg\n",
    "  ps = np.zeros(4, dtype=np.int32)\n",
    "  for tid in range(N):\n",
    "    k_boundary_cpu(n, tid, k - 1, BT, ps)\n",
    "    i,j,q,_= ps\n",
    "    y[i] += (x[q] - x[j])\n",
    "    y[j] -= (x[j] + x[q])\n",
    "    y[q] += (x[i] - x[j])\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def laplacian2_matvec(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  np.multiply(x, deg, y) # y = x * deg\n",
    "  ps = np.zeros(4, dtype=np.int32)\n",
    "  for tid in range(N):\n",
    "    k_boundary_cpu(n, tid, k - 1, BT, ps)\n",
    "    a,b,c,d = ps\n",
    "    y[a] += x[c] - (x[b] + x[d])\n",
    "    y[b] += x[d] - (x[a] + x[c])\n",
    "    y[c] += x[a] - (x[b] + x[d])\n",
    "    y[d] += x[b] - (x[a] + x[c])\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def laplacian3_matvec(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  np.multiply(x, deg, y) # y = x * deg\n",
    "  ps = np.zeros(5, dtype=np.int32)\n",
    "  for tid in range(N):\n",
    "    k_boundary_cpu(n, tid, k - 1, BT, ps)\n",
    "    a,b,c,d,e = ps\n",
    "    y[a] += (x[c] + x[e]) - (x[b] + x[d])\n",
    "    y[b] += x[d] - (x[a] + x[c] + x[e])\n",
    "    y[c] += (x[a] + x[e]) - (x[b] + x[d])\n",
    "    y[d] += x[b] - (x[a] + x[c] + x[e])\n",
    "    y[e] += (x[a] + x[c]) - (x[b] + x[d])\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def laplacian4_matvec(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  np.multiply(x, deg, y) # y = x * deg\n",
    "  ps = np.zeros(6, dtype=np.int32)\n",
    "  for tid in range(N):\n",
    "    k_boundary_cpu(n, tid, k - 1, BT, ps)\n",
    "    a,b,c,d,e,f = ps\n",
    "    y[a] += x[c] + x[e] - (x[b] + x[d] + x[f])\n",
    "    y[b] += x[d] + x[f] - (x[a] + x[c] + x[e])\n",
    "    y[c] += x[a] + x[e] - (x[b] + x[d] + x[f])\n",
    "    y[d] += x[b] + x[f] - (x[a] + x[c] + x[e])\n",
    "    y[e] += x[a] + x[c] - (x[b] + x[d] + x[f])\n",
    "    y[f] += x[b] + x[d] - (x[a] + x[c] + x[e])\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def laplacian5_matvec(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  np.multiply(x, deg, y) # y = x * deg\n",
    "  ps = np.zeros(7, dtype=np.int32)\n",
    "  for tid in range(N):\n",
    "    k_boundary_cpu(n, tid, k - 1, BT, ps)\n",
    "    a,b,c,d,e,f,g = ps\n",
    "    y[a] += x[c] + x[e] + x[g] - (x[b] + x[d] + x[f])\n",
    "    y[b] += x[d] + x[f] - (x[a] + x[c] + x[e] + x[g])\n",
    "    y[c] += x[a] + x[e] + x[g] - (x[b] + x[d] + x[f])\n",
    "    y[d] += x[b] + x[f] - (x[a] + x[c] + x[e] + x[g])\n",
    "    y[e] += x[a] + x[c] + x[g] - (x[b] + x[d] + x[f])\n",
    "    y[f] += x[b] + x[d] - (x[a] + x[c] + x[e] + x[g])\n",
    "    y[g] += x[a] + x[c] + x[e] - (x[b] + x[d] + x[f])\n",
    "\n",
    "@nb.jit(nopython=True, boundscheck=do_bounds_check)\n",
    "def precompute_deg(n: int, k: int, N: int, M: int, BT: np.ndarray) -> np.ndarray:\n",
    "  deg = np.zeros(N)\n",
    "  k_faces = np.zeros(k, dtype=np.int32)\n",
    "  for r in range(M):\n",
    "    k_boundary_cpu(n, simplex=r, dim=k-1, BT=BT, out=k_faces)\n",
    "    deg[k_faces] += 1\n",
    "  return deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Taf2RlRWufY",
    "outputId": "ec720094-6ab9-455d-9e0a-5fd7821b3b0b"
   },
   "outputs": [],
   "source": [
    "from combin import rank_to_comb, comb_to_rank\n",
    "from itertools import combinations\n",
    "from math import comb\n",
    "n, k = 8, 3\n",
    "N, M = comb(n,k-1), comb(n,k)\n",
    "BT = np.array([[comb(ni, ki) for ni in range(n)] for ki in range(k+2)]).astype(np.int64)\n",
    "deg = precompute_deg(n,k,N,M,BT)\n",
    "assert np.all(deg == (np.ones(comb(n,k-1)) * (n - k + 1)))\n",
    "print(deg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MZ_Z-iRY1wY"
   },
   "outputs": [],
   "source": [
    "import cupy\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "# def get_max(top: int, bottom: int, pred: Callable, *args):\n",
    "def get_max_cuda(top: int, bottom: int, r: int, m: int, BT: np.ndarray) -> int:\n",
    "  # if ~pred(bottom, *args):\n",
    "  if not(BT[m][bottom] <= r):\n",
    "    return bottom\n",
    "  size = (top - bottom)\n",
    "  while (size > 0):\n",
    "    step = size >> 1\n",
    "    mid = top - step\n",
    "    if not(BT[m][mid] <= r):\n",
    "      top = mid - 1\n",
    "      size -= step + 1\n",
    "    else:\n",
    "      size = step\n",
    "  return top\n",
    "\n",
    "# @cuda.jit(device=True)\n",
    "# def find_k_pred(w: int, r: int, m: int, BT: np.ndarray) -> bool:\n",
    "#   return BT[m][w] <= r\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def get_max_vertex_cuda(r: int, m: int, n: int, BT: np.ndarray) -> int:\n",
    "  k_lb: int = m - 1\n",
    "  # return 1 + get_max(n, k_lb, find_k_pred, r, m, BT)\n",
    "  return 1 + get_max_cuda(n, k_lb, r, m, BT)\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def k_boundary(n: int, simplex: int, dim: int, BT: np.ndarray, out: np.ndarray):\n",
    "  idx_below: int = simplex\n",
    "  idx_above: int = 0\n",
    "  j = n - 1\n",
    "  for kr in range(dim+1):\n",
    "    k = dim - kr\n",
    "    j = get_max_vertex_cuda(idx_below, k + 1, j, BT) - 1\n",
    "    c = BT[k+1][j]\n",
    "    face_index = idx_above - c + idx_below\n",
    "    idx_below -= c\n",
    "    idx_above += BT[k][j]\n",
    "    out[kr] = face_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pT2uxEIyX5Lt"
   },
   "outputs": [],
   "source": [
    "from numba import int64, float64\n",
    "\n",
    "@cuda.jit\n",
    "def laplacian1_matvec_cuda(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "  ps = cuda.local.array(shape=(4,), dtype=int64)\n",
    "\n",
    "  if tid < N:\n",
    "    k_boundary(n, tid, k - 1, BT, ps)\n",
    "    i, j, q = ps[0], ps[1], ps[2]\n",
    "    cuda.atomic.add(y, i, x[q] - x[j])\n",
    "    cuda.atomic.add(y, j, -(x[j] + x[q]))\n",
    "    cuda.atomic.add(y, q, x[i] - x[j])\n",
    "\n",
    "@cuda.jit\n",
    "def laplacian2_matvec_cuda(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  tid = (cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x)\n",
    "  ps = cuda.local.array(shape=(4,), dtype=int64)\n",
    "\n",
    "  if tid < N:\n",
    "    k_boundary(n, tid, k - 1, BT, ps)\n",
    "    a,b,c,d = ps[0], ps[1], ps[2], ps[3]\n",
    "    cuda.atomic.add(y, a, x[c] - (x[b] + x[d]))\n",
    "    cuda.atomic.add(y, b, x[d] - (x[a] + x[c]))\n",
    "    cuda.atomic.add(y, c, x[a] - (x[b] + x[d]))\n",
    "    cuda.atomic.add(y, d, x[b] - (x[a] + x[c]))\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def laplacian3_matvec_cuda(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  # cp.multiply(x, deg, y) # y = x * deg\n",
    "  tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "  ps = cuda.local.array(shape=(5,), dtype=int64)\n",
    "  if tid < N:\n",
    "    k_boundary(n, tid, k - 1, BT, ps)\n",
    "    a,b,c,d,e = ps[0], ps[1], ps[2], ps[3], ps[4]\n",
    "    cuda.atomic.add(y, a, (x[c] + x[e]) - (x[b] + x[d]))\n",
    "    cuda.atomic.add(y, b, x[d] - (x[a] + x[c] + x[e]))\n",
    "    cuda.atomic.add(y, c, (x[a] + x[e]) - (x[b] + x[d]))\n",
    "    cuda.atomic.add(y, d, x[b] - (x[a] + x[c] + x[e]))\n",
    "    cuda.atomic.add(y, e, (x[a] + x[c]) - (x[b] + x[d]))\n",
    "\n",
    "@cuda.jit\n",
    "def laplacian4_matvec_cuda(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  # tid = cuda.grid(1)\n",
    "  tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "  ps = cuda.local.array(shape=(6,), dtype=int64)\n",
    "  if tid < N:\n",
    "    k_boundary(n, tid, k - 1, BT, ps)\n",
    "    a,b,c,d,e,f = ps[0], ps[1], ps[2], ps[3], ps[4], ps[5]\n",
    "    cuda.atomic.add(y, a, x[c] + x[e] - (x[b] + x[d] + x[f]))\n",
    "    cuda.atomic.add(y, b, x[d] + x[f] - (x[a] + x[c] + x[e]))\n",
    "    cuda.atomic.add(y, c, x[a] + x[e] - (x[b] + x[d] + x[f]))\n",
    "    cuda.atomic.add(y, d, x[b] + x[f] - (x[a] + x[c] + x[e]))\n",
    "    cuda.atomic.add(y, e, x[a] + x[c] - (x[b] + x[d] + x[f]))\n",
    "    cuda.atomic.add(y, f, x[b] + x[d] - (x[a] + x[c] + x[e]))\n",
    "\n",
    "@cuda.jit\n",
    "def laplacian5_matvec_cuda(x: np.ndarray, y: np.ndarray, n: int, k: int, N: int, BT: np.ndarray, deg: np.ndarray):\n",
    "  # tid = cuda.grid(1)\n",
    "  tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "  ps = cuda.local.array(shape=(7,), dtype=int64)\n",
    "  if tid < N:\n",
    "    k_boundary(n, tid, k - 1, BT, ps)\n",
    "    a,b,c,d,e,f,g = ps[0], ps[1], ps[2], ps[3], ps[4], ps[5], ps[6]\n",
    "    cuda.atomic.add(y, a, x[c] + x[e] + x[g] - (x[b] + x[d] + x[f]))\n",
    "    cuda.atomic.add(y, b, x[d] + x[f] - (x[a] + x[c] + x[e] + x[g]))\n",
    "    cuda.atomic.add(y, c, x[a] + x[e] + x[g] - (x[b] + x[d] + x[f]))\n",
    "    cuda.atomic.add(y, d, x[b] + x[f] - (x[a] + x[c] + x[e] + x[g]))\n",
    "    cuda.atomic.add(y, e, x[a] + x[c] + x[g] - (x[b] + x[d] + x[f]))\n",
    "    cuda.atomic.add(y, f, x[b] + x[d] - (x[a] + x[c] + x[e] + x[g]))\n",
    "    cuda.atomic.add(y, g, x[a] + x[c] + x[e] - (x[b] + x[d] + x[f]))\n",
    "\n",
    "# for i in range(len(ps)):\n",
    "#   if ps[i] < 0 or ps[i] > len(x):\n",
    "#   # if a < 0 or a > len(x)\n",
    "#     y[0] = -0.5 # tid #\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evoLOpbTL6sM"
   },
   "outputs": [],
   "source": [
    "from math import comb\n",
    "from numba import float32\n",
    "import cupy as cp\n",
    "\n",
    "def predict_GB(n,k):\n",
    "  return 3 * ((comb(n,k-1) * 4) / 1024**3) + (n*(k+2) * 8) / 1024**3\n",
    "\n",
    "class LaplacianBenchmark():\n",
    "  def __init__(self, n: int, k: int, gpu: bool = False, threadsperblock: int = 32, n_kernels: int = 1):\n",
    "    assert k >= 2, \"k must be at least 2\"\n",
    "    self.tm = np if not gpu else cp\n",
    "    self.n = n # num vertices\n",
    "    self.k = k # dim + 1\n",
    "    self.N = comb(n,k-1)\n",
    "    self.M = comb(n,k)\n",
    "    self._pred_GB = 3 * ((comb(self.n,self.k-1) * 4) / 1024**3) + (self.n*(self.k+2) * 8) / 1024**3\n",
    "    # self.x = cp.ones(self.N)\n",
    "    BT = np.array([[comb(ni, ki) for ni in range(n)] for ki in range(k+2)]).astype(np.int64)\n",
    "\n",
    "\n",
    "    if not gpu:\n",
    "      self.mult = np.multiply\n",
    "      self.deg = np.ones(self.N, dtype=np.float32) * (n - k + 1)\n",
    "      self.BT = BT\n",
    "      if k == 3:\n",
    "        self.launch_config = laplacian1_matvec\n",
    "      elif k == 4:\n",
    "        self.launch_config = laplacian2_matvec\n",
    "      elif k == 5:\n",
    "        self.launch_config = laplacian3_matvec\n",
    "      elif k == 6:\n",
    "        self.launch_config = laplacian4_matvec\n",
    "      elif k == 7:\n",
    "        self.launch_config = laplacian5_matvec\n",
    "      else:\n",
    "        raise ValueError(\"invalid k\")\n",
    "    else:\n",
    "      self.mult = cp.multiply\n",
    "      self.deg = cp.ones(self.N, dtype=np.float32) * (n - k + 1)\n",
    "      self.BT = cp.array(BT)\n",
    "      self.threadsperblock = threadsperblock\n",
    "      self.blockspergrid = ((self.M + (self.threadsperblock - 1)) // threadsperblock) + 1\n",
    "      self.n_kernels = n_kernels\n",
    "      if k == 3:\n",
    "        self.launch_config = laplacian1_matvec_cuda[self.blockspergrid, self.threadsperblock]\n",
    "      elif k == 4:\n",
    "        self.launch_config = laplacian2_matvec_cuda[self.blockspergrid, self.threadsperblock]\n",
    "      elif k == 5:\n",
    "        self.launch_config = laplacian3_matvec_cuda[self.blockspergrid, self.threadsperblock]\n",
    "      elif k == 6:\n",
    "        self.launch_config = laplacian4_matvec_cuda[self.blockspergrid, self.threadsperblock]\n",
    "      elif k == 7:\n",
    "        self.launch_config = laplacian5_matvec_cuda[self.blockspergrid, self.threadsperblock]\n",
    "      else:\n",
    "        raise ValueError(\"invalid k\")\n",
    "\n",
    "  def __repr__(self) -> str:\n",
    "    msg = f\"Up-Laplacian (({self.N} / {self.M})  ({self.k-1}/{self.k})-simplices) \\n\"\n",
    "    msg += f\"n: {self.n}, k: {self.k}, deg: {self.deg[:2]}\\n\"\n",
    "    msg += (f\"Pred memory usage cap: {self._pred_GB:.3f} GB \\n\")\n",
    "    if hasattr(self, \"threadsperblock\"):\n",
    "      msg += f\"threads-per-block: {self.threadsperblock}, blocks-per-thread: {self.blockspergrid}\\n\"\n",
    "    return msg\n",
    "\n",
    "  def __call__(self, x: np.ndarray, y: np.ndarray, offset: int = 0) -> np.ndarray:\n",
    "    assert len(x) == len(self.deg) and len(y) == len(self.deg), \"Invalid dimensions\"\n",
    "    self.mult(x, self.deg, y)\n",
    "    self.launch_config(x, y, self.n, self.k, self.M, self.BT, self.deg)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJqYrXm1MH_3",
    "outputId": "84b8ebe8-530c-433a-9652-76a70007f713"
   },
   "outputs": [],
   "source": [
    "L = LaplacianBenchmark(16, 4, gpu=True, n_kernels=1)\n",
    "print(L)\n",
    "# print(L.tm)\n",
    "x = L.tm.arange(L.N, dtype=np.float32)\n",
    "y = L.tm.zeros(L.N, dtype=np.float32)\n",
    "# L(x,y)\n",
    "# WUT = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c8PegAIj0LW",
    "outputId": "1422dedc-a84c-4581-bffc-e32601719bd4"
   },
   "outputs": [],
   "source": [
    "n,k = 512, 5\n",
    "\n",
    "GB_xyd = 3 * ((comb(n,k-1) * 4) / 1024**3)\n",
    "GB_BT = (n*(k+2) * 8) / 1024**3\n",
    "print(f\"Predicted cap memory usage: {(GB_xyd + GB_BT):.3f} GB (xyd: {GB_xyd:.3f}, BT: {GB_BT:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y16xziINMyTX",
    "outputId": "910a9557-1fc5-4977-967f-9a115b1f7066"
   },
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGnTBIefM2mc",
    "outputId": "10ea649a-1c0c-460e-a035-bf216c92d65d"
   },
   "outputs": [],
   "source": [
    "np.all(y == WUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvPmsamoINpn",
    "outputId": "4cc12215-60db-4155-ee31-74e2c18823ae"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen(\"nvprof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NNVJSYIQy9I",
    "outputId": "c84c3908-ee9d-4fae-c01b-f814cdafb358"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "timings = {}\n",
    "for n in [16,32,64,128,256,512,1024,2048]:\n",
    "  for k in [3,4,5,6,7]:\n",
    "    if predict_GB(n,k) > 12:\n",
    "      continue\n",
    "    L = LaplacianBenchmark(n, k, gpu=True)\n",
    "    x = L.tm.arange(L.N)\n",
    "    y = L.tm.zeros(L.N)\n",
    "    print((n,k))\n",
    "    timings[(n,k)] = timeit.repeat(lambda: L(x,y), number=1, repeat=30)\n",
    "  print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdCOgWhhzpBF"
   },
   "outputs": [],
   "source": [
    "# timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sM4HLUqyGawj",
    "outputId": "c6982c8c-3e5b-43f9-c7e3-78dbe800bf9b"
   },
   "outputs": [],
   "source": [
    "L = LaplacianBenchmark(2056, 3, gpu=True, threadsperblock=32)\n",
    "x = L.tm.arange(L.N)\n",
    "y = L.tm.zeros(L.N)\n",
    "L(x,y)\n",
    "## 44 seconds for 1024, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqwt7TyYGMnx",
    "outputId": "29f86a41-f26b-4a52-c99c-fb7f67568ef4"
   },
   "outputs": [],
   "source": [
    "n,k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zT-bdNgSSWQX"
   },
   "outputs": [],
   "source": [
    "\n",
    "from json import dumps, dump\n",
    "# s = dumps({str(k): v for k, v in timings.items()})\n",
    "\n",
    "timings_ = { str(k) : v for k,v in timings.items()}\n",
    "with open('timings.json', 'w') as fp:\n",
    "    dump(timings_, fp)\n",
    "# np.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrQvdTHhZOrv",
    "outputId": "5bebe1dc-df26-42d1-806c-18799e4d4a8d"
   },
   "outputs": [],
   "source": [
    "threadsperblock = 32\n",
    "blockspergrid = (M + (threadsperblock - 1))\n",
    "print(f\"# blocks: {blockspergrid}, threads per block: {threadsperblock}\")\n",
    "if k == 3:\n",
    "  print(laplacian1_matvec_cuda)\n",
    "  launch_config = laplacian1_matvec_cuda[blockspergrid, threadsperblock]\n",
    "elif k == 4:\n",
    "  print(laplacian2_matvec_cuda)\n",
    "  launch_config = laplacian2_matvec_cuda[blockspergrid, threadsperblock]\n",
    "elif k == 5:\n",
    "  print(laplacian3_matvec_cuda)\n",
    "  launch_config = laplacian3_matvec_cuda[blockspergrid, threadsperblock]\n",
    "elif k == 6:\n",
    "  print(laplacian4_matvec_cuda)\n",
    "  launch_config = laplacian4_matvec_cuda[blockspergrid, threadsperblock]\n",
    "elif k == 7:\n",
    "  print(laplacian5_matvec_cuda)\n",
    "  launch_config = laplacian5_matvec_cuda[blockspergrid, threadsperblock]\n",
    "else:\n",
    "  print(\"INVALID CONFIG\")\n",
    "print(launch_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N46ZGG48kopU",
    "outputId": "48f91221-d9a8-41e5-d3eb-bb6ce17eb19f"
   },
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "# x = cp.ones(comb(n,k-1))\n",
    "x = cp.arange(comb(n,k-1))\n",
    "y = cp.zeros(comb(n,k-1))\n",
    "deg = cp.ones(comb(n,k-1)) * (n - k + 1) #cp.repeat(n - k + 1, comb(n, k-1))\n",
    "\n",
    "print(f\"n: {n}, k: {k}, deg: {deg[:5]}, x: {x[:5]}, y: {y[:5]}\")\n",
    "print(f\"tpb: {threadsperblock}, bpg: {blockspergrid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmlMNkSQl71s",
    "outputId": "fc45ca73-43c3-4be8-a8b1-1eddd1866907"
   },
   "outputs": [],
   "source": [
    "cp.multiply(x, deg, y)\n",
    "print(y)\n",
    "launch_config(x, y, n, k, int(comb(n, k)), BT, deg)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4HDVY6WY7qb"
   },
   "outputs": [],
   "source": [
    "# mempool = cp.get_default_memory_pool()\n",
    "# mempool.free_all_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3R2N4x8uZnZq",
    "outputId": "35ad5589-013f-4a2b-bb0d-020990008c42"
   },
   "outputs": [],
   "source": [
    "# deg = cp.array(precompute_deg(n,k,N,M,BT))\n",
    "x = cp.arange(N)\n",
    "y = cp.zeros(N)\n",
    "BT = cp.array(np.array([[comb(ni, ki) for ni in range(n)] for ki in range(k+2)]).astype(np.int64))\n",
    "deg = cp.ones(comb(n,k-1)) * (n - k + 1)\n",
    "\n",
    "threadsperblock = 32\n",
    "blockspergrid = (M + (threadsperblock - 1))\n",
    "print(f\"n: {n}, k: {k}, deg: {deg[:5]}, x: {x[:5]}, y: {y[:5]}\")\n",
    "print(f\"tpb: {threadsperblock}, bpg: {blockspergrid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqlB2hhZaDaz"
   },
   "outputs": [],
   "source": [
    "cp.multiply(x, deg, y)\n",
    "launch_config(x, y, n, k, int(comb(n, k)), BT, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-H-HtJkaYAO",
    "outputId": "dcf8eadd-d13e-43c1-a50b-5a17d6ba8b19"
   },
   "outputs": [],
   "source": [
    "# print(np.all(y == 0))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcCi3itcZ3Ks"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICPltFeNWEkY",
    "outputId": "cc3b95ee-f836-4f7c-ef41-5b318bf85b83"
   },
   "outputs": [],
   "source": [
    "L = LaplacianBenchmark(64, 7, gpu=True)\n",
    "# print(L.N)\n",
    "# wut = cp.zeros(10) # 64, 6\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oj7XWit3WU-x",
    "outputId": "6382bd88-ad36-4939-eead-c0cc15a673a5"
   },
   "outputs": [],
   "source": [
    "L = LaplacianBenchmark(64, 7, gpu=True)\n",
    "\n",
    "x = L.tm.arange(L.N, dtype=np.float32)\n",
    "y = L.tm.zeros(L.N, dtype=np.float32)\n",
    "L(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pi-NaV3k9eWz"
   },
   "outputs": [],
   "source": [
    "1.5300000e+02, 5.0000000e+02, 5.4500000e+02, ..., 3.6973199e+09,\n",
    "3.8342625e+09, 3.9712087e+09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-nmkGDqAvA4"
   },
   "outputs": [],
   "source": [
    "L = LaplacianBenchmark(64, 6, gpu=False)\n",
    "x = L.tm.arange(L.N)\n",
    "y = L.tm.zeros(L.N)\n",
    "L(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zpxDeROAPey"
   },
   "outputs": [],
   "source": [
    "print(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUIv9PTzWECm"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "\n",
    "timings = {}\n",
    "for n in [16, 32, 64, 128]:\n",
    "  for k in [4,5,6,7]:\n",
    "    L = LaplacianBenchmark(n, k)\n",
    "    x = cp.arange(L.N, dtype=np.float32)\n",
    "    y = cp.zeros(L.N, dtype=np.float32)\n",
    "    print((n,k))\n",
    "    timings[(n,k)] = timeit.timeit(lambda: L(x,y), number=100)\n",
    "  print(n)\n",
    "\n",
    "# 6.  10.  14.  14.  18.   8.  12.   8.  12.  28.  20.  32.   7.  19.\n",
    "#   37. -24. -20. -28. -24.  -4. -16.  -4. -35. -23.  -5.  48.  20.  52.\n",
    "#  -13.  19.  57. -55. -23.  15.  63.\n",
    "# launch_config(x, y, n, k, N, BT, deg)\n",
    "\n",
    "# BT_cuda = cp.array(BT)\n",
    "# def laplacian_matvec_cuda() -> np.ndarray:\n",
    "#   cp.multiply(x, deg, y)\n",
    "#   launch_config(x, y, n, k, N, BT_cuda, deg)\n",
    "#   return y\n",
    "\n",
    "# import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUSSx562zoRY"
   },
   "outputs": [],
   "source": [
    "# timeit.timeit(lambda: laplacian_matvec_cuda(), number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxi8N-qknvr6"
   },
   "outputs": [],
   "source": [
    "# from cupyx.profiler import benchmark\n",
    "\n",
    "# benchmark(laplacian_matvec_cuda, n_repeat=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M99AH11JfUix"
   },
   "outputs": [],
   "source": [
    "from numba import int64, float64\n",
    "\n",
    "@cuda.jit\n",
    "def test_cuda(N: int, out: np.ndarray):\n",
    "  tid = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "  ps = cuda.local.array(shape=(8,), dtype=int64)\n",
    "  if tid < N:\n",
    "    out[tid] = tid\n",
    "  # out[0] = tid if tid > out[0] else out[0]\n",
    "  cuda.atomic.max(out, 0, tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZAd98_gfokk",
    "outputId": "fda3fa3a-7783-4ec0-8685-a993d8329de8"
   },
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "out = cp.zeros(512)\n",
    "threadsperblock = 32\n",
    "blockspergrid = 512 // 32\n",
    "print(f\"# blocks: {blockspergrid}, threads per block: {threadsperblock}\")\n",
    "test_cuda[blockspergrid, threadsperblock](len(out), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SR-81-vEf7aL",
    "outputId": "cd8eb9dc-15a6-4a64-b31d-cb7bb564a884"
   },
   "outputs": [],
   "source": [
    "print(min(out))\n",
    "print(out[0])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zixyCE30gPb5",
    "outputId": "31280947-c3fc-4158-f1f2-83e4ab5f2e3a"
   },
   "outputs": [],
   "source": [
    "2**16"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
